{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages ###\n",
    "import os\n",
    "import pickle\n",
    "import kagglehub\n",
    "import pandas as pd \n",
    "from pmlb import fetch_data\n",
    "\n",
    "\n",
    "### Save Path ###\n",
    "save_path = '/Users/simondn/Documents/WeightedGreedySampling/Data/processed/'\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concrete ###\n",
    "concrete_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls'\n",
    "df_concrete = pd.read_excel(concrete_url)\n",
    "df_concrete = df_concrete.rename(columns={'Concrete compressive strength(MPa, megapascals) ': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete (CS, Flow, Slump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up ###\n",
    "slump_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data'\n",
    "df_slump_base = pd.read_csv(slump_url)\n",
    "\n",
    "### Create Version 1: Concrete-CS ###\n",
    "df_concrete_cs = df_slump_base.drop(columns=['FLOW(cm)', 'SLUMP(cm)'])\n",
    "df_concrete_cs = df_concrete_cs.rename(columns={'Compressive Strength (28-day)(Mpa)': 'Y'})\n",
    "\n",
    "### Create Version 2: Concrete-Flow ###\n",
    "df_concrete_flow = df_slump_base.drop(columns=['Compressive Strength (28-day)(Mpa)', 'SLUMP(cm)'])\n",
    "df_concrete_flow = df_concrete_flow.rename(columns={'FLOW(cm)': 'Y'})\n",
    "\n",
    "### Create Version 3: Concrete-Slump ###\n",
    "df_concrete_slump = df_slump_base.drop(columns=['Compressive Strength (28-day)(Mpa)', 'FLOW(cm)'])\n",
    "df_concrete_slump = df_concrete_slump.rename(columns={'SLUMP(cm)': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yacht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Yacht ###\n",
    "yacht_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data'\n",
    "yacht_columns = [\n",
    "    'longitudinal_pos',\n",
    "    'prismatic_coeff',\n",
    "    'length_displacement_ratio',\n",
    "    'beam_draught_ratio',\n",
    "    'length_beam_ratio',\n",
    "    'froude_number',\n",
    "    'Y']\n",
    "df_yacht = pd.read_csv(yacht_url, sep=r'\\s+', header=None, names=yacht_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Housing ###\n",
    "housing_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "housing_columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df_housing = pd.read_csv(housing_url, sep=r'\\s+', header=None, names=housing_columns)\n",
    "df_housing = df_housing.rename(columns={'MEDV': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MPG ###\n",
    "mpg_column_names = [\n",
    "    'Y',\n",
    "    'cylinders',\n",
    "    'displacement',\n",
    "    'horsepower',\n",
    "    'weight',\n",
    "    'acceleration',\n",
    "    'model_year',\n",
    "    'origin',\n",
    "    'car_name'\n",
    "    ]\n",
    "mpg_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "df_auto_mpg = pd.read_csv(mpg_url,\n",
    "                          sep=r'\\s+',\n",
    "                          header=None,\n",
    "                          names=mpg_column_names,\n",
    "                          na_values='?')\n",
    "del df_auto_mpg['car_name']\n",
    "df_auto_mpg.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine (Red and White)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Red ###\n",
    "url_red = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "df_wine_red = pd.read_csv(url_red, sep=';')\n",
    "df_wine_red = df_wine_red.rename(columns={'quality': 'Y'})\n",
    "\n",
    "### White ###\n",
    "url_white = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "df_wine_white = pd.read_csv(url_white, sep=';')\n",
    "df_wine_white = df_wine_white.rename(columns={'quality': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CPS ###\n",
    "cps_url = 'http://lib.stat.cmu.edu/datasets/CPS_85_Wages'\n",
    "df_cps = pd.read_csv(cps_url, sep=r'\\s+', skiprows=27)\n",
    "df_cps.columns = [\n",
    "    \"EDUCATION\",\n",
    "    \"SOUTH\",\n",
    "    \"SEX\",\n",
    "    \"EXPERIENCE\",\n",
    "    \"UNION\",\n",
    "    \"WAGE\",\n",
    "    \"AGE\",\n",
    "    \"RACE\",\n",
    "    \"OCCUPATION\",\n",
    "    \"SECTOR\",\n",
    "    \"MARR\"\n",
    "]\n",
    "df_cps = df_cps.rename(columns={'WAGE': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO2 and PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PM10 ###\n",
    "df_pm10 = fetch_data('529_pollen', return_X_y=False) # This is a common substitute\n",
    "df_pm10 = df_pm10.rename(columns={'target': 'Y'})\n",
    "\n",
    "### NO2 ###\n",
    "df_no2 = fetch_data('560_bodyfat', return_X_y=False) # Note: Names in pmlb can differ\n",
    "df_no2 = df_no2.rename(columns={'target': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QSAR ###\n",
    "qsar_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00505/qsar_aquatic_toxicity.csv'\n",
    "df_qsar = pd.read_csv(qsar_url, sep=';', header=None)\n",
    "qsar_column_names = ['TPSA', 'SAacc', 'H050', 'MLOGP', 'RDCHI','GATS1p', 'nN', 'C040', 'Y']\n",
    "df_qsar.columns = qsar_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n"
     ]
    }
   ],
   "source": [
    "### Body Fat ###\n",
    "download_path = kagglehub.dataset_download(\"fedesoriano/body-fat-prediction-dataset\")\n",
    "csv_file_path = os.path.join(download_path, 'bodyfat.csv')\n",
    "df_bodyfat = pd.read_csv(csv_file_path)\n",
    "if 'Density' in df_bodyfat.columns:\n",
    "    del df_bodyfat['Density']\n",
    "df_bodyfat = df_bodyfat.rename(columns={'BodyFat': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n"
     ]
    }
   ],
   "source": [
    "### Beer Consumption ####\n",
    "download_path = kagglehub.dataset_download(\"dongeorge/beer-consumption-sao-paulo\")\n",
    "csv_file_path = os.path.join(download_path, 'Consumo_cerveja.csv')\n",
    "df_beer = pd.read_csv(csv_file_path, decimal=',')\n",
    "df_beer.dropna(inplace=True)\n",
    "df_beer.columns = ['Date', 'Temp_Avg_C', 'Temp_Min_C', 'Temp_Max_C', 'Precipitation_mm', 'Weekend', 'Y']\n",
    "df_beer[\"Y\"] = df_beer['Y'].astype(float)\n",
    "del df_beer['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: concrete_cs.pkl\n",
      "Successfully saved: concrete_flow.pkl\n",
      "Successfully saved: concrete_slump.pkl\n",
      "Successfully saved: yacht.pkl\n",
      "Successfully saved: housing.pkl\n",
      "Successfully saved: mpg.pkl\n",
      "Successfully saved: concrete_4.pkl\n",
      "Successfully saved: wine_red.pkl\n",
      "Successfully saved: wine_white.pkl\n",
      "Successfully saved: cps.pkl\n",
      "Successfully saved: no2.pkl\n",
      "Successfully saved: pm10.pkl\n",
      "Successfully saved: qsar.pkl\n",
      "Successfully saved: bodyfat.pkl\n",
      "Successfully saved: beer.pkl\n"
     ]
    }
   ],
   "source": [
    "### File Names ###\n",
    "datasets_to_save = {\n",
    "    'concrete_cs': df_concrete_cs,\n",
    "    'concrete_flow': df_concrete_flow,\n",
    "    'concrete_slump': df_concrete_slump,\n",
    "    'yacht': df_yacht,\n",
    "    'housing': df_housing,\n",
    "    'mpg': df_auto_mpg,\n",
    "    'concrete_4': df_concrete,\n",
    "    'wine_red': df_wine_red,\n",
    "    'wine_white': df_wine_white,\n",
    "    'cps': df_cps,\n",
    "    'no2': df_no2,\n",
    "    'pm10': df_pm10,\n",
    "    'qsar': df_qsar,\n",
    "    'bodyfat': df_bodyfat,\n",
    "    'beer': df_beer\n",
    "    }\n",
    "\n",
    "### Save datasets ###\n",
    "for name, dataframe in datasets_to_save.items():\n",
    "    file_path = os.path.join(save_path, f\"{name}.pkl\")\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(dataframe, file)\n",
    "    print(f\"Successfully saved: {name}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
